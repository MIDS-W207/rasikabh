{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Week 7.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAgifSRPIobR"
      },
      "source": [
        "# Week 7: Text and Natural Language Processing\n",
        "\n",
        "# Rasika Bhalerao\n",
        "\n",
        "# Agenda\n",
        "\n",
        "- [Tensorflow playground](https://playground.tensorflow.org/)\n",
        "- Intro to hw project 3\n",
        "\n",
        "Specifically:\n",
        "- CountVectorizer\n",
        "- fit vs. transform vs. fit_transform\n",
        "- ngrams\n",
        "- stop words\n",
        "- stemming and lemmatization\n",
        "- TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyV4_CyfIi4x"
      },
      "source": [
        "# Imports directly copied from hw\n",
        "\n",
        "# This tells matplotlib not to try opening a new window for each plot.\n",
        "%matplotlib inline\n",
        "\n",
        "# General libraries.\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# SK-learn libraries for learning.\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "# SK-learn libraries for evaluation.\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# SK-learn library for importing the newsgroup data.\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "\n",
        "# SK-learn libraries for feature extraction from text.\n",
        "from sklearn.feature_extraction.text import *\n",
        "\n",
        "import nltk"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "R1NvbQlEXgMV",
        "outputId": "0a7c2727-9b5c-4890-b34f-cafe8edb3ac4"
      },
      "source": [
        "# This is our small dataset from week 3\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    'document': [\n",
        "        'whiskers tail tail paw purr',\n",
        "        'meow whiskers whiskers',\n",
        "        'meow meow paw purr',\n",
        "        'paw bark woof bark',\n",
        "        'paw paw bark bark'\n",
        "    ],\n",
        "    'category': [\n",
        "        'cat', 'cat', 'cat', 'dog', 'dog'\n",
        "    ]\n",
        "})\n",
        "\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>document</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>whiskers tail tail paw purr</td>\n",
              "      <td>cat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>meow whiskers whiskers</td>\n",
              "      <td>cat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>meow meow paw purr</td>\n",
              "      <td>cat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>paw bark woof bark</td>\n",
              "      <td>dog</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>paw paw bark bark</td>\n",
              "      <td>dog</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      document category\n",
              "0  whiskers tail tail paw purr      cat\n",
              "1       meow whiskers whiskers      cat\n",
              "2           meow meow paw purr      cat\n",
              "3           paw bark woof bark      dog\n",
              "4            paw paw bark bark      dog"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zxE8xNLVDcy"
      },
      "source": [
        "###Note: CountVectorizer was imported in this line above:\n",
        "\n",
        "`from sklearn.feature_extraction.text import *`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUgXFmHlJmsJ",
        "outputId": "66239f90-19e2-47d0-e8bb-bf5d2f4ed12a"
      },
      "source": [
        "vectorizer = CountVectorizer()\n",
        "train_docs = np.array(df['document'])\n",
        "\n",
        "vectorizer.fit(train_docs) # make the vectorizer learn the words as features\n",
        "\n",
        "X_train = vectorizer.transform(train_docs) # make the vectorizer transform the training set into numbers\n",
        "\n",
        "# tip: fit_transform(train_docs) = fit and then transform\n",
        "\n",
        "print(f'features: {vectorizer.get_feature_names()}')\n",
        "print(f'X_train:\\n{X_train.toarray()}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features: ['bark', 'meow', 'paw', 'purr', 'tail', 'whiskers', 'woof']\n",
            "X_train:\n",
            "[[0 0 1 1 2 1 0]\n",
            " [0 1 0 0 0 2 0]\n",
            " [0 2 1 1 0 0 0]\n",
            " [2 0 1 0 0 0 1]\n",
            " [2 0 2 0 0 0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nkf6N3TXGLS",
        "outputId": "1cefee42-a1c1-477b-e8ee-39e65e05b545"
      },
      "source": [
        "# train a model, do whatever with those features above representing docs\n",
        "# then consider this test set:\n",
        "\n",
        "test_docs = np.array([\n",
        "  'whiskers bark paw paw paw',\n",
        "  'purr hello'\n",
        "])\n",
        "\n",
        "# What is wrong with the code below? What should we do instead?\n",
        "\n",
        "X_test = vectorizer.fit_transform(test_docs).toarray()\n",
        "\n",
        "print(f'features: {vectorizer.get_feature_names()}')\n",
        "print(f'X:\\n{X_test}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features: ['bark', 'hello', 'paw', 'purr', 'whiskers']\n",
            "X:\n",
            "[[1 0 3 0 1]\n",
            " [0 1 0 1 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjdSSXVkXDIh",
        "outputId": "9cf0b52e-22b8-4449-a338-85de8dba7df0"
      },
      "source": [
        "# ngrams\n",
        "\n",
        "vectorizer = CountVectorizer(\n",
        "    ngram_range=(1,4),\n",
        "    analyzer='word'\n",
        ")\n",
        "\n",
        "docs = np.array([\n",
        "  'whiskers bark paw paw paw',\n",
        "  'purr hello'\n",
        "])\n",
        "X = vectorizer.fit_transform(docs).toarray()\n",
        "\n",
        "print(f'features: {vectorizer.get_feature_names()}')\n",
        "print(f'X:\\n{X}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features: ['bark', 'bark paw', 'bark paw paw', 'bark paw paw paw', 'hello', 'paw', 'paw paw', 'paw paw paw', 'purr', 'purr hello', 'whiskers', 'whiskers bark', 'whiskers bark paw', 'whiskers bark paw paw']\n",
            "X:\n",
            "[[1 1 1 1 0 3 2 1 0 0 1 1 1 1]\n",
            " [0 0 0 0 1 0 0 0 1 1 0 0 0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wu2j6ZeQnJYi",
        "outputId": "14803a8d-23d8-4afc-d900-fe8a80e78d0e"
      },
      "source": [
        "# stop words\n",
        "\n",
        "vectorizer = CountVectorizer(\n",
        "    stop_words=['the', 'a', 'and'],\n",
        "    max_df=1.0,\n",
        "    min_df=0.1,\n",
        "    max_features=None,\n",
        "\n",
        "    lowercase=True,\n",
        "    binary=False\n",
        ")\n",
        "\n",
        "docs = np.array([\n",
        "  'the whiskers bark paw paw paw',\n",
        "  'the purr hello'\n",
        "])\n",
        "X = vectorizer.fit_transform(docs).toarray()\n",
        "\n",
        "print(f'features: {vectorizer.get_feature_names()}')\n",
        "print(f'X:\\n{X}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features: ['bark', 'hello', 'paw', 'purr', 'whiskers']\n",
            "X:\n",
            "[[1 0 3 0 1]\n",
            " [0 1 0 1 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ileeh97GoU3u"
      },
      "source": [
        "### Tip: `stop_words='english'` uses a default english stop word set! But it might not be exactly right for your dataset..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkQzpwvGnn-a",
        "outputId": "1986d403-79a0-4119-ccd2-17912e6ac029"
      },
      "source": [
        "# stemming\n",
        "\n",
        "stemmer = nltk.stem.PorterStemmer()\n",
        "print(stemmer.stem('cats'))\n",
        "print(stemmer.stem('cat'))\n",
        "print(stemmer.stem('purrs'))\n",
        "print(stemmer.stem('purring'))\n",
        "print(stemmer.stem('does'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cat\n",
            "cat\n",
            "purr\n",
            "pur\n",
            "doe\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PR5c6qfLqxZh",
        "outputId": "6e14c46a-fd2e-4ed0-d2b0-356feb3dd643"
      },
      "source": [
        "# lemmatization\n",
        "\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onjoKanHpfd9",
        "outputId": "83b91101-3835-45da-fb27-cb5e9fabd7a0"
      },
      "source": [
        "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
        "print(lemmatizer.lemmatize('cats', pos='n'))\n",
        "print(lemmatizer.lemmatize('cat', pos='n'))\n",
        "print(lemmatizer.lemmatize('purrs', pos='v'))\n",
        "print(lemmatizer.lemmatize('purring', pos='v'))\n",
        "print(lemmatizer.lemmatize('purred', pos='v'))\n",
        "print(lemmatizer.lemmatize('does', pos='v'))\n",
        "print(lemmatizer.lemmatize('is', pos='v'))\n",
        "print(lemmatizer.lemmatize('friendlier', pos='a'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cat\n",
            "cat\n",
            "purr\n",
            "purr\n",
            "purr\n",
            "do\n",
            "be\n",
            "friendly\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rx8v9nvTsIDR"
      },
      "source": [
        "### TfidfVectorizer was imported in the same line as CountVectorizer!\n",
        "\n",
        "TF = term frequency\n",
        "- this is the same as the CountVectorizer word count\n",
        "\n",
        "IDF = inverse document frequency\n",
        "- the reciprocal of the fraction of documents that have this word\n",
        "\n",
        "Tf-IDF = TF * IDF for each word\n",
        "- the elementwise product of the TF and IDF vectors (each word in the vocab is an element)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSSe3UpSpm5k",
        "outputId": "fab699a7-af00-4ebe-82d9-67a10d421061"
      },
      "source": [
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "X_train = vectorizer.fit_transform(train_docs)\n",
        "\n",
        "print(f'features: {vectorizer.get_feature_names()}')\n",
        "print(f'X_train:\\n{X_train}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features: ['bark', 'meow', 'paw', 'purr', 'tail', 'whiskers', 'woof']\n",
            "X_train:\n",
            "  (0, 3)\t0.3403486372984673\n",
            "  (0, 2)\t0.23766482637991668\n",
            "  (0, 4)\t0.843706726582144\n",
            "  (0, 5)\t0.3403486372984673\n",
            "  (1, 1)\t0.4472135954999579\n",
            "  (1, 5)\t0.8944271909999159\n",
            "  (2, 1)\t0.85376425497417\n",
            "  (2, 3)\t0.426882127487085\n",
            "  (2, 2)\t0.29809100315256176\n",
            "  (3, 6)\t0.5050077256599805\n",
            "  (3, 0)\t0.8148741065505222\n",
            "  (3, 2)\t0.2845125436553228\n",
            "  (4, 0)\t0.8198869039412204\n",
            "  (4, 2)\t0.5725255144931797\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hugUlUosXuJ",
        "outputId": "f8703370-3046-4616-debc-99207f14129f"
      },
      "source": [
        "# make it a dense matrix (easier to look at)\n",
        "\n",
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "print(f'features: {vectorizer.get_feature_names()}')\n",
        "print(f'X_train:\\n{csr_matrix.todense(X_train)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features: ['bark', 'meow', 'paw', 'purr', 'tail', 'whiskers', 'woof']\n",
            "X_train:\n",
            "[[0.         0.         0.23766483 0.34034864 0.84370673 0.34034864\n",
            "  0.        ]\n",
            " [0.         0.4472136  0.         0.         0.         0.89442719\n",
            "  0.        ]\n",
            " [0.         0.85376425 0.298091   0.42688213 0.         0.\n",
            "  0.        ]\n",
            " [0.81487411 0.         0.28451254 0.         0.         0.\n",
            "  0.50500773]\n",
            " [0.8198869  0.         0.57252551 0.         0.         0.\n",
            "  0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OUK1tP5tK3m"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
